{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bf0613-d6ec-4cf4-87e5-062fd3bd3a82",
   "metadata": {},
   "source": [
    "### Installation\n",
    "Install the packages required for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f1d825-84cc-43ac-9fe2-f204d77f0962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp>2\n",
      "  Downloading kfp-2.14.6-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting google-cloud-pipeline-components>2\n",
      "  Downloading google_cloud_pipeline_components-2.21.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.124.0-py2.py3-none-any.whl.metadata (45 kB)\n",
      "     ---------------------------------------- 0.0/45.2 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 41.0/45.2 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 45.2/45.2 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting click==8.1.8 (from kfp>2)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting click-option-group==0.5.7 (from kfp>2)\n",
      "  Downloading click_option_group-0.5.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3 (from kfp>2)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from kfp>2)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth<3,>=1.6.1 (from kfp>2)\n",
      "  Downloading google_auth-2.42.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-cloud-storage<4,>=2.2.1 (from kfp>2)\n",
      "  Downloading google_cloud_storage-3.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting kfp-pipeline-spec<3,>=2.14.3 (from kfp>2)\n",
      "  Downloading kfp_pipeline_spec-2.14.6-py3-none-any.whl.metadata (433 bytes)\n",
      "Collecting kfp-server-api<3,>=2.14.3 (from kfp>2)\n",
      "  Downloading kfp-server-api-2.14.6.tar.gz (64 kB)\n",
      "     ---------------------------------------- 0.0/64.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 64.3/64.3 kB 3.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kubernetes<31,>=8.0.0 (from kfp>2)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf<7.0,>=6.31.1 (from kfp>2)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp>2) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=0.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp>2) (1.0.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp>2) (0.9.0)\n",
      "Requirement already satisfied: urllib3<3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp>2) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click==8.1.8->kfp>2) (0.4.6)\n",
      "Requirement already satisfied: Jinja2<4,>=3.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-pipeline-components>2) (3.1.4)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_bigquery-3.38.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.1.2-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_genai-1.47.0-py3-none-any.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.8/46.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.11.7)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp>2)\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp>2) (2.32.2)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.1->kfp>2) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.1->kfp>2) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.1->kfp>2)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting packaging>=14.3 (from google-cloud-aiplatform)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4,>=2.2.1->kfp>2)\n",
      "  Downloading google_crc32c-1.7.1-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.1.2->google-cloud-pipeline-components>2) (2.1.3)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp-server-api<3,>=2.14.3->kfp>2) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp-server-api<3,>=2.14.3->kfp>2) (2025.8.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes<31,>=8.0.0->kfp>2) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes<31,>=8.0.0->kfp>2)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes<31,>=8.0.0->kfp>2)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from shapely<3.0.0->google-cloud-aiplatform) (1.26.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp>2) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp>2) (2.0.4)\n",
      "Downloading kfp-2.14.6-py3-none-any.whl (374 kB)\n",
      "   ---------------------------------------- 0.0/374.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 143.4/374.0 kB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 337.9/374.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 374.0/374.0 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 98.2/98.2 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading click_option_group-0.5.7-py3-none-any.whl (11 kB)\n",
      "Downloading google_cloud_pipeline_components-2.21.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading google_cloud_aiplatform-1.124.0-py2.py3-none-any.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.1 MB 5.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/8.1 MB 6.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/8.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/8.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/8.1 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/8.1 MB 5.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.9/8.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.3/8.1 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.7/8.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.0/8.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.3/8.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.6/8.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.9/8.1 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.2/8.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.3/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.5/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.0/8.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.4/8.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "   ---------------------------------------- 0.0/173.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 173.7/173.7 kB ? eta 0:00:00\n",
      "Downloading google_auth-2.42.1-py2.py3-none-any.whl (222 kB)\n",
      "   ---------------------------------------- 0.0/222.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 222.6/222.6 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery-3.38.0-py3-none-any.whl (259 kB)\n",
      "   ---------------------------------------- 0.0/259.3 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 235.5/259.3 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 259.3/259.3 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
      "   ---------------------------------------- 0.0/397.2 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 358.4/397.2 kB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 397.2/397.2 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-3.4.1-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 290.1/290.1 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading google_genai-1.47.0-py3-none-any.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 241.5/241.5 kB 15.4 MB/s eta 0:00:00\n",
      "Downloading kfp_pipeline_spec-2.14.6-py3-none-any.whl (9.6 kB)\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.7 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.9/1.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.5/66.5 kB ? eta 0:00:00\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/436.9 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 256.0/436.9 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 436.9/436.9 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading shapely-2.1.2-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.7 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 109.1/109.1 kB ? eta 0:00:00\n",
      "Downloading google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.7.1-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.6/294.6 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.6/4.7 MB 9.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.8/4.7 MB 7.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.1/4.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.4/4.7 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.8/4.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.8/4.7 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.1/4.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.5/4.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.1/4.7 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.1/160.1 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 176.8/176.8 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: kfp-server-api\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-2.14.6-py3-none-any.whl size=115734 sha256=c8b60dee7d2eb4787fce212af6b9899b83fbdddc265b1bd0cb09075e0835d6c2\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ndplswhu\\wheels\\4c\\86\\3d\\1ba342199095dbdf57459cbbe65054529d8a4e2a7b2a865ea8\n",
      "Successfully built kfp-server-api\n",
      "Installing collected packages: websockets, tenacity, shapely, rsa, protobuf, packaging, oauthlib, grpcio, google-crc32c, docstring-parser, click, anyio, requests-oauthlib, proto-plus, kfp-server-api, kfp-pipeline-spec, httpx, googleapis-common-protos, google-resumable-media, google-auth, click-option-group, kubernetes, grpcio-status, google-genai, google-api-core, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "Successfully installed anyio-4.11.0 click-8.1.8 click-option-group-0.5.7 docstring-parser-0.17.0 google-api-core-2.28.1 google-auth-2.42.1 google-cloud-aiplatform-1.124.0 google-cloud-bigquery-3.38.0 google-cloud-core-2.5.0 google-cloud-pipeline-components-2.21.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.4.1 google-crc32c-1.7.1 google-genai-1.47.0 google-resumable-media-2.7.2 googleapis-common-protos-1.71.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 httpx-0.28.1 kfp-2.14.6 kfp-pipeline-spec-2.14.6 kfp-server-api-2.14.6 kubernetes-30.1.0 oauthlib-3.3.1 packaging-25.0 proto-plus-1.26.1 protobuf-6.33.0 requests-oauthlib-2.0.0 rsa-4.9.1 shapely-2.1.2 tenacity-9.1.2 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script websockets.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dsl-compile.exe and kfp.exe are installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tb-gcp-uploader.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.32.0 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --user --no-cache-dir --upgrade \"kfp>2\" \"google-cloud-pipeline-components>2\" \\\n",
    "                                        google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc6a21-604f-4a52-b904-e3bb18a61b2f",
   "metadata": {},
   "source": [
    "## Restart the kernel\n",
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dad0c4-c173-46b8-bf99-d6e8efc35316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2207b06-771f-4dbb-a713-90c50745c0ea",
   "metadata": {},
   "source": [
    "## Check the versions of the packages you installed. The KFP SDK version should be >2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b60838-e5a2-41cd-ae93-43925343fba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Apps > Advanced app settings > App execution aliases.\n",
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Apps > Advanced app settings > App execution aliases.\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0bcff2-3ffb-4e51-b852-511cb10ad0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "import typing\n",
    "from typing import Dict\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "import google.cloud.aiplatform as aip\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afffb0-449b-4669-807a-793f526277fe",
   "metadata": {},
   "source": [
    "#### Project and Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf6aad4-f675-47aa-820b-14daa796d89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The Google Cloud project that this pipeline runs in.\n",
    "PROJECT_ID = \"data-engineering-1-473218\"\n",
    "# The region that this pipeline runs in\n",
    "REGION = \"europe-west4\"\n",
    "# Specify a Cloud Storage URI that your pipelines service account can access. The artifacts of your pipeline runs are stored within the pipeline root.\n",
    "PIPELINE_ROOT = \"gs://ass1_temp_bucket/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8a366-76c3-4f17-b760-f012dfacaf02",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1a411c-2f31-45ae-89f8-f394c3157fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\",\"tensorflow\",\"scikit-learn\", \"fsspec\",\"gcsfs\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def train_model(data_bucket:str, output_model: Output[Model]):\n",
    "    \"\"\"\n",
    "    Function takes data file from the data bucket and trains a simple MLP model on it.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import pandas as pd\n",
    "    from tensorflow import keras\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    random.seed(67)\n",
    "\n",
    "    # 1. Load dataset from data bucket\n",
    "    #url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "    cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "    #df = pd.read_csv(url, header=None, names=cols)\n",
    "    \n",
    "    df = pd.read_csv(f\"gs://{data_bucket}/data_banknote_authentication.txt\", header=None, names=cols)\n",
    "\n",
    "    X = df[[\"variance\", \"skewness\", \"curtosis\", \"entropy\"]].values\n",
    "    y = df[\"class\"].values\n",
    "\n",
    "    # 2. Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3. Normalize inside the model (so we don’t need a separate scaler)\n",
    "    normalizer = keras.layers.Normalization()\n",
    "    normalizer.adapt(X_train)\n",
    "\n",
    "    # 4. Build simple MLP model\n",
    "    model = keras.Sequential([\n",
    "        normalizer,\n",
    "        keras.layers.Dense(8, activation=\"relu\"),\n",
    "        keras.layers.Dense(4, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 5. Train model\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=8, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # 6. Evaluate model\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\" Test accuracy: {acc:.3f}\")\n",
    "\n",
    "    # 7. Save model in the same folder\n",
    "    model.save(output_model.path + \".keras\")\n",
    "    \n",
    "    # 8. Add metadata\n",
    "    metadata = {\n",
    "        \"accuracy\": acc,\n",
    "        \"algo\": \"MLP\",\n",
    "        \"file_type\": \".keras\"\n",
    "    }\n",
    "        \n",
    "    # 9. Attach metadata to Vertex artifact (for pipelines)\n",
    "    output_model.metadata.update(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e16e7-962a-46c3-8957-009267d1256c",
   "metadata": {},
   "source": [
    "### Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b7759b-d6bb-437c-86a4-d817187ed834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def compare_model(new_model: Input[Model], model_bucket_metadata: str) -> str:\n",
    "    \"\"\"\n",
    "    Function compares local model to existing one in model bucket\n",
    "    :returns: \"NEW\" if accuracy of the new model is better, \"EXISTING\" if the old one is better.\n",
    "    \"\"\"\n",
    "    import json, tempfile, os\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    # Get new model accuracy\n",
    "    new_accuracy = float(new_model.metadata.get(\"accuracy\", 0))\n",
    "\n",
    "    # Get old model accuracy\n",
    "    bucket_name, blob_path = model_bucket_metadata.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_path)\n",
    "    \n",
    "    # Temporarily download the older model from the model bucket\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False)\n",
    "    blob.download_to_filename(tmp.name)\n",
    "    with open(tmp.name, \"r\") as f:\n",
    "        old_metadata = json.load(f)\n",
    "        \n",
    "    old_accuracy = float(old_metadata[\"accuracy\"])\n",
    "    \n",
    "    os.remove(tmp.name)\n",
    "    # Check whether the new model outperforms the old one\n",
    "    decision = \"NEW\" if new_accuracy > old_accuracy else \"EXISTING\"\n",
    "    return decision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbccdc87-7aab-46f5-a4e5-6b24a8ad8060",
   "metadata": {},
   "source": [
    "### Upload Model and Metrics to Google Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9344f481-88ca-4220-a0af-3a055c61455b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def upload_model_to_gcs(project_id: str, model_repo: str, model: Input[Model])->str:\n",
    "    \"\"\"\n",
    "    Function uploads model and metadata .json\n",
    "    \"\"\"\n",
    "    from google.cloud import storage\n",
    "    from urllib.parse import urlparse\n",
    "    import json\n",
    "    import os\n",
    "    import tempfile\n",
    "    \n",
    "\n",
    "    # parse gs://...\n",
    "    p = urlparse(model_repo) if model_repo.startswith(\"gs://\") else None\n",
    "    bucket_name = (p.netloc if p else model_repo.split(\"/\",1)[0])\n",
    "    prefix = (p.path.lstrip(\"/\") if p else (model_repo.split(\"/\",1)[1] if \"/\" in model_repo else \"\"))\n",
    "\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # model path from artifact\n",
    "    ext = str(model.metadata.get(\"file_type\", \".keras\"))\n",
    "    algo = str(model.metadata.get(\"algo\", \"model\"))\n",
    "    src_model = model.path + ext\n",
    "    dst_model = \"/\".join(filter(None, [prefix, f\"{algo}_model{ext}\"]))\n",
    "    bucket.blob(dst_model).upload_from_filename(src_model)\n",
    "\n",
    "    # create & upload metadata json from artifact metadata\n",
    "    meta = dict(model.metadata)\n",
    "    with tempfile.NamedTemporaryFile(\"w\", delete=False) as f:\n",
    "        json.dump(meta, f, indent=4)\n",
    "        tmp_meta = f.name\n",
    "    dst_meta = \"/\".join(filter(None, [prefix, \"model_metadata.json\"]))\n",
    "    bucket.blob(dst_meta).upload_from_filename(tmp_meta)\n",
    "\n",
    "    return f\"gs://{bucket_name}/{dst_model}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166590b3-f788-4e4c-8e31-fb981da56966",
   "metadata": {},
   "source": [
    "#### Define the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96b6ae0-234b-4883-ae95-8599689a5e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the workflow of the pipeline.\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"banknote-authentication-training-pipeline\")\n",
    "def pipeline(project_id: str, data_bucket: str, model_repo: str, model_bucket_metadata: str):\n",
    "    \"\"\"\n",
    "    Building the pipeline\n",
    "    \"\"\"\n",
    "    # New stuff\n",
    "    training_mlp_job_run_op = train_model(\n",
    "        data_bucket = data_bucket\n",
    "    )\n",
    "    \n",
    "    compare_model_job_run_op = compare_model(\n",
    "        new_model = training_mlp_job_run_op.outputs[\"output_model\"],\n",
    "        model_bucket_metadata = model_bucket_metadata\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    with dsl.If(compare_model_job_run_op.output == \"NEW\"):\n",
    "        upload_model_to_gcs(\n",
    "            project_id = project_id,\n",
    "            model_repo = model_repo,\n",
    "            model = training_mlp_job_run_op.outputs[\"output_model\"]\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Old stuff\n",
    "    \n",
    "    di_op = download_data(\n",
    "        project_id=project_id,\n",
    "        bucket=data_bucket,\n",
    "        file_name=trainset_filename\n",
    "    )\n",
    "\n",
    " \n",
    "    training_mlp_job_run_op = train_mlp(\n",
    "        features=di_op.outputs[\"dataset\"]\n",
    "    )\n",
    "    \n",
    "     \n",
    "    training_lr_job_run_op = train_lr(\n",
    "        features=di_op.outputs[\"dataset\"]\n",
    "    )\n",
    "    \n",
    "    pre_di_op = download_data(\n",
    "        project_id=project_id,\n",
    "        bucket=data_bucket,\n",
    "        file_name=testset_filename\n",
    "    ).after(training_mlp_job_run_op, training_lr_job_run_op)\n",
    "        \n",
    "        \n",
    "    comp_model__op = compare_model(mlp_metrics=training_mlp_job_run_op.outputs[\"metrics\"],\n",
    "                                       lr_metrics=training_lr_job_run_op.outputs[\"metrics\"]).after(training_mlp_job_run_op, training_lr_job_run_op)  \n",
    "    \n",
    "    # defining the branching condition\n",
    "    with dsl.If(comp_model__op.output==\"MLP\"):\n",
    "        predict_mlp_job_run_op = predict_mlp(\n",
    "            model=training_mlp_job_run_op.outputs[\"out_model\"],      \n",
    "            features=pre_di_op.outputs[\"dataset\"]\n",
    "        )\n",
    "        upload_model_mlp_to_gc_op = upload_model_to_gcs(\n",
    "            project_id=project_id,\n",
    "            model_repo=model_repo,\n",
    "            model=training_mlp_job_run_op.outputs['out_model']\n",
    "        ).after(predict_mlp_job_run_op)\n",
    "        \n",
    "    with dsl.If(comp_model__op.output==\"LR\"):\n",
    "        predict_lr_job_run_op = predict_lr(\n",
    "            model=training_lr_job_run_op.outputs[\"out_model\"],     \n",
    "            features=pre_di_op.outputs[\"dataset\"]\n",
    "        )\n",
    "        upload_model_lr_to_gc_op = upload_model_to_gcs(\n",
    "            project_id=project_id,\n",
    "            model_repo=model_repo,\n",
    "            model=training_lr_job_run_op.outputs['out_model']\n",
    "        ).after(predict_lr_job_run_op) \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac278200-c580-4f40-bc8b-1817d3b13c13",
   "metadata": {},
   "source": [
    "#### Compile the pipeline into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ee4b21-89e6-4f63-845c-b249556ea919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import compiler\n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='cloudbuild-mlops.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87025e-08d7-4608-b37d-c929b6eb5a3c",
   "metadata": {},
   "source": [
    "#### Submit the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83b88e89-42cd-4e64-bc4e-8e3eddebccff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "# Before initializing, make sure to set the GOOGLE_APPLICATION_CREDENTIALS\n",
    "# environment variable to the path of your service account.\n",
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    staging_bucket=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# Prepare the pipeline job\n",
    "job = aip.PipelineJob(\n",
    "    display_name=\"banknote-authentication-training-pipeline\",\n",
    "    enable_caching=False,\n",
    "    template_path=\"cloudbuild-mlops.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    location=REGION,\n",
    "    parameter_values={\n",
    "        'project_id': PROJECT_ID, # makesure to use your project id \n",
    "        'data_bucket': 'ass1_data_bucket',  # makesure to use your data bucket name \n",
    "        'model_repo':'gs://ass1_model_bucket', # makesure to use your model bucket name\n",
    "        'model_bucket_metadata': 'gs://ass1_model_bucket/model_metadata.json'\n",
    "    }\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
